{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Importing libraries"]},{"cell_type":"code","execution_count":null,"id":"4f774d96","metadata":{},"outputs":[],"source":["%pip install pandas seaborn scikit-learn scikit-plot\n","import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE"]},{"attachments":{},"cell_type":"markdown","id":"ed903b84","metadata":{},"source":["# Loading and Checking the dataset"]},{"attachments":{},"cell_type":"markdown","id":"d43418ae","metadata":{},"source":["We chose UNSW_NB15 dataset for this IDS project.\n","\n","This is the link for [UNSW_NB15 dataset](https://www.kaggle.com/datasets/mrwellsdavid/unsw-nb15).\n","\n","The training and testing sets were reversed, so we changed the names before loading them from CSV files."]},{"cell_type":"code","execution_count":null,"id":"f5909ec0","metadata":{"scrolled":true},"outputs":[],"source":["df_train = pd.read_csv(\"./UNSW_NB15/UNSW_NB15_training-set.csv\")\n","df_test = pd.read_csv(\"./UNSW_NB15/UNSW_NB15_testing-set.csv\")\n","print(\"Length of training set: \", len(df_train))\n","print(\"Length of testing set: \", len(df_test))"]},{"attachments":{},"cell_type":"markdown","id":"9d8ed2fa","metadata":{},"source":["In order to ensure the balance between the training and testing sets and avoid processing twice, we decided to concatenate them into one dataframe and redivide them with a different ratio later with *sklearn.model_selection.train_test_split()*."]},{"cell_type":"code","execution_count":null,"id":"b93d3084","metadata":{"scrolled":true},"outputs":[],"source":["df = pd.concat([df_train, df_test])\n","# information about the dataset\n","df.info()"]},{"cell_type":"code","execution_count":null,"id":"8d4b6e60","metadata":{},"outputs":[],"source":["df.describe(include=\"all\")"]},{"cell_type":"code","execution_count":null,"id":"9c26aab2","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"id":"fefb18aa","metadata":{},"outputs":[],"source":["# Remove unnecessary features\n","df.drop([\"proto\", \"service\", \"state\", ], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"eb0b39ee","metadata":{},"outputs":[],"source":["df['attack_cat'].value_counts().plot.bar()"]},{"attachments":{},"cell_type":"markdown","id":"5dcba1e2","metadata":{},"source":["Replace labels with the following mapping:"]},{"cell_type":"code","execution_count":null,"id":"cbe30d97","metadata":{},"outputs":[],"source":["df['attack_cat'] = df['attack_cat'].replace(['Normal', 'Generic', 'Exploits','Fuzzers', 'DoS','Reconnaissance', 'Analysis', 'Backdoor', 'Shellcode', 'Worms'], ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n","df['attack_cat'] = df['attack_cat'].astype(int)\n","df.info()"]},{"attachments":{},"cell_type":"markdown","id":"29a3e975","metadata":{},"source":["# Upscale samples for poisoning detection"]},{"cell_type":"code","execution_count":null,"id":"be90d4a8","metadata":{},"outputs":[],"source":["# Separate the features and labels\n","y = df['attack_cat']\n","X = df.drop(['attack_cat', 'label'], axis=1)\n","# Create a dictionary to store the target number of samples for each class\n","target_samples = {0: 400000, 1: 100000}\n","# Initialize the SMOTE oversampler\n","smote = SMOTE(sampling_strategy=target_samples)\n","# Upsample the dataset\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","# Create a new DataFrame with the resampled data\n","df_resampled = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled, columns=['attack_cat'])], axis=1)\n","# Verify the class distribution after upsampling\n","print(df_resampled['attack_cat'].value_counts())"]},{"cell_type":"code","execution_count":null,"id":"5c55b957","metadata":{},"outputs":[],"source":["df_resampled"]},{"attachments":{},"cell_type":"markdown","id":"8043ea22","metadata":{},"source":["# Print dataset to files with expected format"]},{"cell_type":"code","execution_count":null,"id":"eac76767","metadata":{},"outputs":[],"source":["# Print the label column into Y_attack.npy\n","y = y_resampled.to_numpy()\n","np.save(\"Y_attack.npy\", y)\n","# Print others columns into X.npy\n","X = X_resampled.to_numpy()\n","np.save(\"X.npy\", X)"]},{"attachments":{},"cell_type":"markdown","id":"7a2eeeb1","metadata":{},"source":["## Checking for duplicates"]},{"cell_type":"code","execution_count":null,"id":"a5879461","metadata":{},"outputs":[],"source":["print(df.duplicated().sum())"]},{"attachments":{},"cell_type":"markdown","id":"4b58f842","metadata":{},"source":["There is no duplicate record."]},{"attachments":{},"cell_type":"markdown","id":"e0bb94f1","metadata":{},"source":["## Checking for missing values"]},{"cell_type":"code","execution_count":null,"id":"1447e477","metadata":{"scrolled":true},"outputs":[],"source":["print(df.isna().sum())"]},{"attachments":{},"cell_type":"markdown","id":"61e39b47","metadata":{},"source":["There is no missing value."]},{"attachments":{},"cell_type":"markdown","id":"e13ff4ed","metadata":{},"source":["## Checking the balance between benign and attack data"]},{"cell_type":"code","execution_count":null,"id":"e4facbf4","metadata":{},"outputs":[],"source":["df['label'].value_counts().plot.bar()"]},{"cell_type":"code","execution_count":null,"id":"a1176c2d","metadata":{},"outputs":[],"source":["df['label'].value_counts(normalize=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The ratio between attack and normal data is not equal, but just slightly imbalanced.\n","Therefore, we will not do a sampling fix here."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":5}
